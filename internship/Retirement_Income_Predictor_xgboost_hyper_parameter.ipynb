{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "002c8191"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import warnings\n",
        "import statsmodels.api as sm #Cross-sectional models and methods.\n",
        "import statsmodels.formula.api as smf #A convenience interface for specifying models using formula strings and DataFrames.\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import sklearn\n",
        "# Function to deal with missing values via imputation\n",
        "from sklearn.impute import SimpleImputer\n",
        "# Function that converts categorical values into numerical values via ordinal encoding or one-hot encoding\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
        "# Function to split data into different groups\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.linear_model import *\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "import random\n",
        "import math\n",
        "from scipy.stats import pointbiserialr, spearmanr\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# for logit regression. \n",
        "# statsmodel is chosen because it outputs descriptive stats for the model\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# for SVM\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Statistics functions\n",
        "from scipy.stats import norm\n",
        "from scipy import stats\n",
        "from scipy.stats import chi2_contingency\n",
        "# Suppressing a warning \n",
        "warnings.filterwarnings(\"ignore\") \n",
        "\n",
        "# It is a magic function that renders the figure in the notebook\n",
        "%matplotlib inline \n",
        "\n",
        "# The style parameters control properties like the color of the background and whether a grid is enabled by default.\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "id": "002c8191"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46895a2d"
      },
      "source": [
        "#### 1.1.2. Loading the Data sets "
      ],
      "id": "46895a2d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c635fdd",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('nedgroup_training_data.csv') # importing the training data\n",
        "df_validation = pd.read_csv('nedgroup_validation_data.csv') # importing the validation data\n",
        "df_test = pd.read_csv('nedgroup_testing_data.csv') # importing the testing data"
      ],
      "id": "9c635fdd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "347166aa"
      },
      "source": [
        "Seeing that we have some features with null values that are almost have of the total values in the features, we will to drop them; not just because of the null values but because after research done on this project we realized that those features which are; `GENDER`,`SPOUSE _GENDER`, `SPOUSE_RETIREMENT_AGE`, `SPOUSE_DATE_OF_BIRTH` will add no value to the prediction of the `RETIREMENT_FUND_VALUE`."
      ],
      "id": "347166aa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38b79549"
      },
      "outputs": [],
      "source": [
        "def drop_features(df):\n",
        "  df = df.drop(df[['PERCENTAGE_SUCCESS','LA_EAC_PA_INCL_VAT', 'CONFIDENCE_LEVEL', 'RETIREMENT_AGE', 'SPOUSE_RETIREMENT_AGE', 'Unnamed: 0', 'SPOUSE_DATE_OF_BIRTH', 'SPOUSE_GENDER', 'HAS_EMERGENCY_SAVINGS', 'CRITICAL_ILLNESS', 'GENDER', 'FINANCIALLY_SUPPORT_PARTNER', 'FINANCIALLY_SUPPORT_CHILDREN']], axis=1)\n",
        "  return df\n",
        "\n",
        "df_train = drop_features(df_train)\n",
        "df_test = drop_features(df_test)\n",
        "df_validation = drop_features(df_validation)"
      ],
      "id": "38b79549"
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train.fillna(0)\n",
        "df_validation = df_validation.fillna(0)\n",
        "df_test = df_test.fillna(0)"
      ],
      "metadata": {
        "id": "ktRSzHFb7YvS"
      },
      "id": "ktRSzHFb7YvS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accumulated_value(df):\n",
        "  df['ANNUAL_CHILD_VALUE'] = df['CHILD_MONTHLY_SUPPORTING_VALUE'] * 12\n",
        "  df['ACCUMULATED_CHILD_VALUE'] = df['ANNUAL_CHILD_VALUE'] * df['YEARS_SUPPORTING_CHILD']\n",
        "  df['ANNUAL_OTHER_VALUE'] = df['OTHER_MONTHLY_SUPPORTING_VALUE'] * 12\n",
        "  df['ACCUMULATED_OTHER_VALUE'] = df['ANNUAL_OTHER_VALUE'] * df['YEARS_SUPPORTING_SOMEONE_ELSE']\n",
        "  df['AANUAL_NET_INCOME'] = df['CURRENT_NET_MONTHLY_INCOME'] * 12\n",
        "  df = df.drop(df[['CURRENT_NET_MONTHLY_INCOME', 'ANNUAL_CHILD_VALUE', 'CHILD_MONTHLY_SUPPORTING_VALUE', 'YEARS_SUPPORTING_CHILD', 'ANNUAL_OTHER_VALUE', 'OTHER_MONTHLY_SUPPORTING_VALUE', 'YEARS_SUPPORTING_SOMEONE_ELSE']], axis=1)\n",
        "  return df"
      ],
      "metadata": {
        "id": "heiABRwRgWlS"
      },
      "id": "heiABRwRgWlS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = accumulated_value(df_train)\n",
        "df_test = accumulated_value(df_test)\n",
        "df_validation = accumulated_value(df_validation)"
      ],
      "metadata": {
        "id": "15o6X_l7hbA3"
      },
      "id": "15o6X_l7hbA3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_real_values(df):\n",
        "    df['ONGOING_COACHING_FEE'] = round(df['ONGOING_COACHING_FEE']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    df['INITIAL_PLANNER_FEE_INCL_VAT_UT'] = round(df['INITIAL_PLANNER_FEE_INCL_VAT_UT']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    df['INITIAL_PLANNER_FEE_INCL_VAT_LA_AND_LAP'] = round(df['INITIAL_PLANNER_FEE_INCL_VAT_LA_AND_LAP']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    df['ONGOING_PLANNER_FEE_INCL_VAT_UT'] = round(df['ONGOING_PLANNER_FEE_INCL_VAT_UT']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    df['ONGOING_PLANNER_FEE_INCL_VAT_LA_AND_LAP'] = round(df['ONGOING_PLANNER_FEE_INCL_VAT_LA_AND_LAP']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    df['SA_EQUITY_UNIT_TRUST'] = round(df['SA_EQUITY_UNIT_TRUST']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    df['SA_BOND_UNIT_TRUST'] = round(df['SA_BOND_UNIT_TRUST']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    df['SA_CASH_UNIT_TRUST'] = round(df['SA_CASH_UNIT_TRUST']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    df['INTERNATIONAL_EQUITY_UNIT_TRUST'] = round(df['INTERNATIONAL_EQUITY_UNIT_TRUST']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    df['INTERNATIONAL_BOND_UNIT_TRUST'] = round(df['INTERNATIONAL_BOND_UNIT_TRUST']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    df['INTERNATIONAL_CASH_UNIT_TRUST'] = round(df['INTERNATIONAL_CASH_UNIT_TRUST']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    df['SA_EQUITY_LAP'] = round(df['SA_EQUITY_LAP']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    df['SA_BOND_LAP'] = round(df['SA_BOND_LAP']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    df['SA_CASH_LAP'] = round(df['SA_CASH_LAP']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    df['INTERNATIONAL_EQUITY_LAP'] = round(df['INTERNATIONAL_EQUITY_LAP']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    df['INTERNATIONAL_BOND_LAP'] = round(df['INTERNATIONAL_BOND_LAP']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    df['INTERNATIONAL_CASH_LAP'] = round(df['INTERNATIONAL_CASH_LAP']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    df['LAP_EAC_PA_INCL_VAT'] = round(df['LAP_EAC_PA_INCL_VAT']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    df['UNIT_TRUST_EAC_PA_INCL_VAT'] = round(df['UNIT_TRUST_EAC_PA_INCL_VAT']/100 * df['RETIREMENT_FUND_VALUE'])\n",
        "    return df"
      ],
      "metadata": {
        "id": "vDeNcA4uhcZe"
      },
      "id": "vDeNcA4uhcZe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = get_real_values(df_train)\n",
        "df_test = get_real_values(df_test)\n",
        "df_validation = get_real_values(df_validation)"
      ],
      "metadata": {
        "id": "lBzO5La0hc8f"
      },
      "id": "lBzO5La0hc8f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7zcsSHRgCNFM"
      },
      "id": "7zcsSHRgCNFM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df_train.drop(['RETIREMENT_FUND_VALUE'], axis=1)\n",
        "X_test = df_test.drop(['RETIREMENT_FUND_VALUE'], axis=1)\n",
        "y_train = df_train['RETIREMENT_FUND_VALUE']\n",
        "y_test = df_test['RETIREMENT_FUND_VALUE']"
      ],
      "metadata": {
        "id": "9ZI1xlYee0e_"
      },
      "id": "9ZI1xlYee0e_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train2 = X_train.copy()\n",
        "\n",
        "scaler = StandardScaler() # instantiate the scaler function\n",
        "X_train = scaler.fit_transform(X_train) \n",
        "# convert the scaled predictor values into a dataframe\n",
        "X_train = pd.DataFrame(X_train,columns=X_train2.columns)\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiEE0q5yARgQ",
        "outputId": "cd7e18de-f6d5-4310-8f6b-6f57c4355848"
      },
      "id": "IiEE0q5yARgQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23944, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test2 = X_test.copy()\n",
        "\n",
        "# instantiate the scaler function\n",
        "X_test = scaler.transform(X_test) \n",
        "# convert the scaled predictor values into a dataframe\n",
        "X_test = pd.DataFrame(X_test,columns=X_test2.columns)\n",
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JArE0T_tDCGT",
        "outputId": "4a519d28-8e47-4197-8c23-711c110956ed"
      },
      "id": "JArE0T_tDCGT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3420, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "H-vyj6xbGskM"
      },
      "id": "H-vyj6xbGskM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l0GtlPpQGqdX"
      },
      "id": "l0GtlPpQGqdX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05c9f1c1"
      },
      "outputs": [],
      "source": [
        "#===========================================================================\n",
        "# set up our regressor. Today we shall be using the xgboost\n",
        "#===========================================================================\n",
        "import xgboost as xg\n",
        "xgb = xg.XGBRegressor()\n",
        "\n",
        "#===========================================================================\n",
        "# perform a scikit-learn Recursive Feature Elimination (RFE)\n",
        "#===========================================================================\n",
        "from sklearn.feature_selection import RFE\n",
        "# here we want only one final feature, we do this to produce a ranking\n",
        "n_features_to_select = 1\n",
        "rfe = RFE(xgb, n_features_to_select=n_features_to_select)\n",
        "rfe.fit(X_train, y_train)\n",
        "\n",
        "#===========================================================================\n",
        "# now print out the features in order of ranking\n",
        "#===========================================================================\n",
        "from operator import itemgetter\n",
        "features = X_train.columns.to_list()\n",
        "for x, y in (sorted(zip(rfe.ranking_ , features), key=itemgetter(0))):\n",
        "    print(x, y)"
      ],
      "id": "05c9f1c1"
    },
    {
      "cell_type": "code",
      "source": [
        "#===========================================================================\n",
        "# ok, this time let's choose the top 10 featues and use them for the model\n",
        "#===========================================================================\n",
        "n_features_to_select = 13\n",
        "\n",
        "rfe = RFE(xgb, n_features_to_select=n_features_to_select)\n",
        "rfe.fit(X_train, y_train)\n",
        "\n",
        "#===========================================================================\n",
        "# use the model to predict the prices for the test data\n",
        "#===========================================================================\n",
        "predictions = rfe.predict(X_test)"
      ],
      "metadata": {
        "id": "LktZduaV9yC4"
      },
      "id": "LktZduaV9yC4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'R2 For Random Forest Regressor:  {r2_score(y_test, predictions)}')\n",
        "\n",
        "def rmse(y_test, y_predict):\n",
        "    mse = mean_squared_error(y_test, y_predict)\n",
        "    rmse = mse**0.5\n",
        "    return rmse\n",
        "print(f'Random Forest Regressor RMSE:  {rmse(y_test, predictions)}')"
      ],
      "metadata": {
        "id": "DU1sii127xts"
      },
      "id": "DU1sii127xts",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions1 = rfe.predict(X_train)\n",
        "print(f'Random Forest Regressor RMSE:  {rmse(y_train, predictions1)}')\n",
        "print(f'R2 For Random Forest Regressor:  {r2_score(y_train, predictions1)}')"
      ],
      "metadata": {
        "id": "ok8G4yBQuykU"
      },
      "id": "ok8G4yBQuykU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e449d5aa"
      },
      "source": [
        "## Hyper Parameter Tunning"
      ],
      "id": "e449d5aa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f89c9e4c"
      },
      "source": [
        "**XGBoost Regressor Hyper Parameter Tunning**"
      ],
      "id": "f89c9e4c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bc0670b"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# Define the grid of hyperparameters to search\n",
        "\n",
        "param_grid = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
        "              'objective':['reg:linear'],\n",
        "              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
        "              'max_depth': [5, 6, 7, 10],\n",
        "              'min_child_weight': [2, 3, 4],\n",
        "              'booster': ['gblinear', 'gbtree'],\n",
        "              'silent': [1],\n",
        "              'subsample': [0.7],\n",
        "              'colsample_bytree': [0.7],\n",
        "              'n_estimators': [100, 500, 900, 1100, 1500]}\n",
        "\n",
        "\n",
        "xgb_grid = GridSearchCV(xgb1,\n",
        "                        param_grid,\n",
        "                        cv = 10,\n",
        "                        n_jobs = 5,\n",
        "                        verbose=True)"
      ],
      "id": "9bc0670b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e73ece75"
      },
      "outputs": [],
      "source": [
        "xgb_grid.fit(X_train,y_train)"
      ],
      "id": "e73ece75"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "700a00bc"
      },
      "outputs": [],
      "source": [
        "print(xgb_grid.best_score_)\n",
        "print(xgb_grid.best_params_)"
      ],
      "id": "700a00bc"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 46.294,
      "end_time": "2022-05-30T07:34:45.962965",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-05-30T07:33:59.668965",
      "version": "2.3.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}